name: "MDPhysics"

arch: 
  _target_: model.MDPhysics.DPT
  cfg:
    backbone:
      name: "facebook/dinov3-vitb16-pretrain-lvd1689m"  # HuggingFace model identifier
      freeze: true  # Freeze backbone weights
      patch_size: 16  # DINOv3 uses 16x16 patches
      embed_dim: 768  # Hidden dimension (auto-detected if available)

    decoder:
      features: 256  # Feature dimension for decoder
      feature_layers: [2, 5, 8, 11]  # Layers to extract features from (for base: 12 layers total)
      scales: [4, 8, 16, 32]  # Output scales for each reassembled feature
      fusion_channels: [64, 128, 256, 256] # Explicit channel widths for fusion blocks [Block 0, Block 1, Block 2, Block 3]
      separate_sharp_head: false # Whether to use a separate fusion path for the sharp image head
      read_operation: "project"  # Options: "ignore", "add", "project"
      use_bn: false  # Use batch normalization in fusion blocks
      use_deconv: false  # Use transposed conv for upsampling

    heads:
      use_bn: false  # Use batch normalization in prediction heads

    depth_prior:
      checkpoint: "depth-anything/da3-large"
      freeze_backbone: true
      default_focal_length: 700.0

    use_blurring_block: true
    used_image_blurring_block: "GT" # or pred

    ssm:
      d_state: 64
      d_conv: 4
      expand: 2
      n_layer: 2
